---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi! My name is Zekun Li (ÊùéÊ≥ΩÂù§). I am a second-year Ph.D. student in Computer Science at [Brown University](https://www.brown.edu/), working with [Prof. Srinath Sridhar](https://cs.brown.edu/people/ssrinath/index.html) at [Interactive 3D Vision & Learning Lab](https://ivl.cs.brown.edu/).

Before studying at Brown, I received my B. Eng. degree with honors in Computer Science at the University of Electronic Science and Technology of China ([UESTC](https://www.uestc.edu.cn/)). My undergraduate research advisor is [Prof. Zhao Kang](https://zhaokang.site/). Previously, I have enriched my research experience as an intern at [Tencent AI Lab](https://ai.tencent.com/ailab/en/index) and [Honda Research Institute](https://usa.honda-ri.com/).

My research interest focuses on Generative Models and Computer Graphics. I am keen on combining knowledge-based principles and learning-based networks to achieve robust, responsible, controllable, and creative models for visual content generation.
Recently, I mainly focused on vision content customization and human-X interaction.

<!-- I am looking for research internship for 24 Summer, here is my [CV](images/CV_ZekunLi.pdf). Please freely contact me without any hesitation! (‚óã'‚ó°'‚óã)Ôæâ  -->
I'm always open to collaboration. If you want to work with me, please contact me without hesitation! (‚óã'‚ó°'‚óã)Ôæâ


<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV2024</div><img src='images/SurfD.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Surf-D: High-Quality Surface Generation for Arbitrary Topologies using Diffusion Models**

Zhengming Yu, Zhiyang Dou, Xiaoxiao Long, Cheng Lin, <b><u>Zekun Li</u></b>, Yuan Liu, Norman M√ºller, Taku Komura, Marc Habermann, Christian Theobalt, Xin Li, Wenping Wang
<br>
[[paper]](https://arxiv.org/abs/2311.17050)    [[project]](https://yzmblog.github.io/projects/SurfD/)

**TL;DR:** Design a novel UDF-based latent diffusion model for shape generation.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR2024</div><img src='images/MANUS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**MANUS: Markerless Grasp Capture using Articulated 3D Gaussians**

Chandradeep Pokhariya, Ishaan Nikhil Shah, Angela Xing, <b><u>Zekun Li</u></b>, Kefan Chen, Avinash Sharma, Srinath Sridhar
<br>
[[paper]](https://arxiv.org/abs/2312.02137)    [[project]](https://ivl.cs.brown.edu/research/manus.html)

**TL;DR:** Provide a new multi-view grasping dataset with contact annotation and articulated Gaussian hand model for the benchmark.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR2023</div><img src='images/AnchorDEF.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Learning Anchor Transformations for 3D Garment Animation**

Fang Zhao, <b><u>Zekun Li</u></b>, Shaoli Huang, Junwu Weng, Tianfei Zhou, Guosen Xie, Jue Wang, Ying Shan
<br>
[[paper]](https://arxiv.org/abs/2304.00761)    [[project]](https://semanticdh.github.io/AnchorDEF/)

**TL;DR:** Design adaptive anchors to predict 3D garment animation from a body motion sequence, especially for loose-fitting garments.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV2022</div><img src='images/SGA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Eliminating Gradient Conflict in Reference-based Line-art Colorization**

<b><u>Zekun Li</u></b>, Zhengyang Geng, Zhao Kang, Wenyu Chen, and Yibo  Yang
<br>
[[paper]](https://arxiv.org/abs/2207.06095)    [[code]](https://github.com/kunkun0w0/SGA)

**TL;DR:** Design a novel BP scheme to solve the gradient issue in Attention.
</div>
</div>

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üí¨ Professional Service
- *Conference Reviewer*: CVPR 2024, SIGGRAPH 2024, ECCV2024, AAAI 2025, ICLR 2025
- *Google explore CSR*: Ph.D. mentor 2024


# üìñ Educations
- *2023.09 - 2028.06 (expected)*, <b>Ph.D. in Computer Science</b>, [Brown University](https://www.brown.edu/).
- *2019.09 - 2023.06*, <b>B. Eng. Degree in Computer Science</b>, University of Electronic Science and Technology of China ([UESTC](https://www.uestc.edu.cn/)).


# üíª Internships
- *2024.6 - 2024.8*, Research Intern, [Honda Research Institute](https://usa.honda-ri.com/), working on human-object-interaction tracking with [Enna Sachdeva](https://ennasachdeva.github.io/).
- *2022.10 - 2023.6*, Research Intern, [Tencent AI Lab](https://ai.tencent.com/ailab/en/index), working on garment animation and generation, supervied by [Prof. Fang Zhao](https://zhaofang0627.github.io/).
- *2020.09 - 2022.09*, Research Intern, Cognitive Computing and Intelligent Decision Lab at [UESTC](https://www.uestc.edu.cn/), working on image translation, supervied by [Prof. Zhao Kang](https://zhaokang.site/).
